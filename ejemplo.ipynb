{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificadores Scikit-Learn\n",
    "\n",
    "https://scikit-learn.org/stable/\n",
    "\n",
    "### Etapas en el ajuste de una máquina de aprendizaje\n",
    "\n",
    "1. Selección de características\n",
    "2. Selección de una métrica de desempeño\n",
    "3. Selección de un clasificador y su algoritmo de optimización\n",
    "4. Evaluar el desempeño del modelo\n",
    "5. Afinamiento y ajustes de los parámetros del algoritmo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conjuntos de datos almacenados en Toolbox\n",
    "from sklearn import datasets  \n",
    "# Separación del conjunto de datos en conjunto de entrenamiento y test\n",
    "from sklearn.model_selection import train_test_split \n",
    "# Método para reescalar los datos\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Paquete numérico para el procesamiento de datos\n",
    "import numpy as np\n",
    "# Paquete para realizar los gráficos \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datos del IRIS\n",
    "Corresponde a una especie de planta con 3 tipos de caregorías: setosa, versicolor y virgínica.\n",
    "A cada planta se le midieron características de estructuras: logitud y ancho del sépalo, y longitud y ancho del pétalo. \n",
    "https://archive.ics.uci.edu/ml/datasets/Iris\n",
    "\n",
    "<img src=\"iris.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "# Para los datos de entrada sólo utilizaremos 2 atributos \n",
    "# con el fin de poder graficar los resultados\n",
    "X = iris.data[:, [2,3]]\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico de dispersión para obervar los datos que se tienen\n",
    "d_clase0 = X[y==0]\n",
    "d_clase1 = X[y==1]\n",
    "d_clase2 = X[y==2]\n",
    "etiquetas = np.unique(y)\n",
    "plt.plot(d_clase0[:,0],d_clase0[:,1], 'r.')\n",
    "plt.plot(d_clase1[:,0],d_clase1[:,1], 'g.')\n",
    "plt.plot(d_clase2[:,0],d_clase2[:,1], 'b.')\n",
    "plt.legend(iris.target_names)\n",
    "plt.title(\"Gráfico de dispersión de los datos del iris\")\n",
    "plt.xlabel(iris.feature_names[2])\n",
    "plt.ylabel(iris.feature_names[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import seaborn as sns\n",
    "#sns.scatterplot(x=X[:,0], y=X[:,1], hue=y)\n",
    "sns.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Separación de los datos en conjunto de entrenamiento y test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_entrenamiento, X_test, y_entrenamiento, y_test = train_test_split(X, y, \n",
    "                        test_size = 0.4, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reescalamiento de las características**\n",
    "\n",
    "Con el fin de que todos los atributos tenga igual importancia al entrenar un clasificador, y debido a que los clasificadores están optimizados para los datos escalados. Procederemos a reescalar los datos.\n",
    "\n",
    "En particular, el escalamiento que se aplicará es centrar los datos en 0 y cambiar su variabilidad a 1:\n",
    "\n",
    "$$Z=\\frac{X - \\overline{X}}{S_{X}}$$\n",
    "\n",
    "donde $\\overline{X}$ corresponde al promedio de los datos y $S_{X}$ a la desviación estándar de los datos de entrada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "# Los datos son reescalado con respecto a los datos de entrenamiento\n",
    "sc.fit(X_entrenamiento) \n",
    "# Tanto el conjunto de entrenamiento como el de test son reescalados\n",
    "Z_entrenamiento = sc.transform(X_entrenamiento)\n",
    "Z_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construcción del clasificador LDA (Linear Discriminant Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clasificador1 = LinearDiscriminantAnalysis()\n",
    "clasificador1.fit(Z_entrenamiento,y_entrenamiento)\n",
    "y_pred1 = clasificador1.predict(Z_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construcción del clasificador QDA (Quadratic Discriminant Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "clasificador2 = QuadraticDiscriminantAnalysis()\n",
    "clasificador2.fit(Z_entrenamiento,y_entrenamiento)\n",
    "y_pred2 = clasificador2.predict(Z_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construcción de un clasificador SVC (Support Vector Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "clasificador3=SVC(kernel='linear', C=0.025)\n",
    "clasificador3.fit(Z_entrenamiento,y_entrenamiento)\n",
    "y_pred3 = clasificador3.predict(Z_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    classes = classes[unique_labels(y_true, y_pred)]\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "confusion_matrix(y_test, y_pred3)\n",
    "plot_confusion_matrix(y_test, y_pred3, classes = iris.target_names, title='Confusion matrix, without normalization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico de dispersión para obervar los datos que se tienen\n",
    "d_err_clas = X_test[y_pred3!=y_test]\n",
    "d_clase0 = X[y==0]\n",
    "d_clase1 = X[y==1]\n",
    "d_clase2 = X[y==2]\n",
    "etiquetas = np.unique(y)\n",
    "plt.plot(d_clase0[:,0],d_clase0[:,1], 'r.')\n",
    "plt.plot(d_clase1[:,0],d_clase1[:,1], 'g.')\n",
    "plt.plot(d_clase2[:,0],d_clase2[:,1], 'b.')\n",
    "plt.scatter(d_err_clas[:,0],d_err_clas[:,1], c='k')\n",
    "plt.legend(iris.target_names)\n",
    "plt.title(\"Gráfico de dispersión de los datos del iris\")\n",
    "plt.xlabel(iris.feature_names[2])\n",
    "plt.ylabel(iris.feature_names[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
